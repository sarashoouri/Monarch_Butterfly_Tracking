{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mobicom_Temp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GmuETEP4tlZ"
      },
      "source": [
        "**Data loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHOCDLs-4vG-"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "class dataloader_light(data.Dataset):\n",
        "\n",
        "    def __init__(self, filename):\n",
        "\n",
        "        self.mat_data = sio.loadmat(filename)\n",
        "        self.data = self.mat_data['data']\n",
        "        self.labels = self.mat_data['label']\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        intensity = self.data[index].astype('double')\n",
        "        label = self.labels[index]\n",
        "\n",
        "        pair = {'intensity': intensity, 'label': label}\n",
        "        return pair\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.mat_data['data'].shape[0]\n",
        "\n",
        "\n",
        "class dataloader_tmp(data.Dataset):\n",
        "\n",
        "    def __init__(self, filename):\n",
        "\n",
        "        self.mat_data = sio.loadmat(filename)\n",
        "        self.data = self.mat_data['tmp_set']\n",
        "        self.labels = self.mat_data['labels']\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        temp = self.data[index].astype('double')\n",
        "        label = self.labels[index][0]\n",
        "\n",
        "        pair = {'temp': temp, 'label': label}\n",
        "        return pair\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.mat_data['tmp_set'].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFNX67-E4wr3"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlxftc9V40LB"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import asarray as ar\n",
        "from numpy import sqrt\n",
        "from numpy.random import rand, randn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        N = x.shape[0]\n",
        "        return x.view(N, -1)\n",
        "\n",
        "\n",
        "class Sandwich(nn.Module):\n",
        "    def __init__(self, c_in, c_out, filter_size):\n",
        "        super(Sandwich, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(c_in, c_out, filter_size, stride=1, padding=(filter_size - 1) // 2),\n",
        "            nn.BatchNorm1d(c_out),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class CNN_Light(nn.Module):\n",
        "    def __init__(self, length, channel, num_layers, num_neu, pdrop):\n",
        "        super(CNN_Light, self).__init__()\n",
        "\n",
        "        self.len = length\n",
        "\n",
        "        blocks = [Sandwich(1, channel, 7)]\n",
        "        self.len = self.len // 2\n",
        "        for _ in range(num_layers - 1):\n",
        "            blocks.append(Sandwich(channel, channel, 3))\n",
        "            self.len = self.len // 2\n",
        "\n",
        "        blocks.append(Flatten())\n",
        "        blocks.append(nn.Linear(self.len * channel, num_neu))\n",
        "        blocks.append(nn.ReLU())\n",
        "        blocks.append(nn.Dropout(p=pdrop))\n",
        "        blocks.append(nn.Linear(num_neu, num_neu))\n",
        "        blocks.append(nn.ReLU())\n",
        "        blocks.append(nn.Dropout(p=pdrop))\n",
        "        blocks.append(nn.Linear(num_neu, 1))\n",
        "\n",
        "        self.net = nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class CNN_Light_lite(nn.Module):\n",
        "    def __init__(self, length, channel, num_layers, num_neu, pdrop):\n",
        "        super(CNN_Light_lite, self).__init__()\n",
        "\n",
        "        self.len = length\n",
        "\n",
        "        blocks = [Sandwich(1, channel, 3)]\n",
        "        self.len = self.len // 2\n",
        "        for _ in range(num_layers - 1):\n",
        "            blocks.append(Sandwich(channel, channel, 3))\n",
        "            self.len = self.len // 2\n",
        "\n",
        "        blocks.append(nn.Conv1d(channel, 1, 1, stride=1))\n",
        "\n",
        "        self.net = nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return torch.mean(self.net(x).squeeze(), dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "class CNN_Temp(nn.Module):\n",
        "    def __init__(self, size, pdrop, num_neu):\n",
        "        super(CNN_Temp, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.drop = nn.Dropout(p=pdrop)\n",
        "\n",
        "        self.fc1 = nn.Linear(size, num_neu)\n",
        "        self.fc2 = nn.Linear(num_neu, num_neu)\n",
        "        self.fc3 = nn.Linear(num_neu, num_neu)\n",
        "        self.fc4 = nn.Linear(num_neu, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.fc1(x)            # Din = 16*256, Dout = 1024\n",
        "        x = self.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)            # Din = 16*256, Dout = 1024\n",
        "        x = self.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc3(x)            # Din = 1024, Dout = 1024\n",
        "        x = self.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CNN_hybrid(nn.Module):\n",
        "    def __init__(self, size, isdrop=0):\n",
        "        super(CNN_hybrid, self).__init__()\n",
        "        # Cin = 1, Cout = 256, Kernel_size = 11\n",
        "        self.relu = nn.ReLU()\n",
        "        self.isdrop = isdrop\n",
        "        #self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        #self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        if self.isdrop == 1:\n",
        "            self.drop = nn.Dropout(p=0.25)\n",
        "        self.fc1 = nn.Linear(size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.fc1(x)            # Din = 16*256, Dout = 1024\n",
        "        x = self.relu(x)\n",
        "        if self.isdrop == 1:\n",
        "            x = self.drop(x)\n",
        "        x = self.fc2(x)            # Din = 1024, Dout = 1024\n",
        "        x = self.relu(x)\n",
        "        if self.isdrop == 1:\n",
        "            x = self.drop(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class CNN_large(nn.Module):\n",
        "    def __init__(self, length, isdrop):\n",
        "        super(CNN_large, self).__init__()\n",
        "        # Cin = 1, Cout = 256, Kernel_size = 11\n",
        "        self.isdrop = isdrop\n",
        "\n",
        "        self.conv1 = nn.Conv1d(1, 64, 3, stride=1, padding=1)\n",
        "        # Cin = 256, Cout = 256, Kernel_size = 5\n",
        "        self.conv2 = nn.Conv1d(64, 128, 3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv1d(128, 128, 3, stride=1, padding=1)\n",
        "\n",
        "        # Batch Nromalization\n",
        "        self.batnorm1 = nn.BatchNorm1d(64)\n",
        "        self.batnorm2 = nn.BatchNorm1d(128)\n",
        "        self.batnorm3 = nn.BatchNorm1d(128)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.maxpool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        if self.isdrop == 1:\n",
        "            self.drop = nn.Dropout(p=0.25)\n",
        "\n",
        "        self.len = length\n",
        "\n",
        "        self.fc1 = nn.Linear(int(self.len / 8) * 128, 128)\n",
        "\n",
        "        #self.fc1 = nn.Linear(self.len, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)          # Cin = 1, Cout = 64, Kernel_size = 11\n",
        "        x = self.batnorm1(x)\n",
        "        x = self.relu(x)\n",
        "        if self.isdrop == 1:\n",
        "            x = self.drop(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        x = self.conv2(x)          # Cin = 64, Cout = 128, Kernel_size = 5\n",
        "        x = self.batnorm2(x)\n",
        "        x = self.relu(x)\n",
        "        if self.isdrop == 1:\n",
        "            x = self.drop(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = self.conv3(x)          # Cin = 64, Cout = 128, Kernel_size = 5\n",
        "        x = self.batnorm3(x)\n",
        "        x = self.relu(x)\n",
        "        if self.isdrop == 1:\n",
        "            x = self.drop(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = x.view(-1, int(self.len / 8) * 128)\n",
        "        #x = x.squeeze(1)\n",
        "        x = self.fc1(x)            # Din = 16*256, Dout = 1024\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)            # Din = 1024, Dout = 1024\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)            # Din = 1024, Dout = 1\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qocEu925A_N"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "WINDOW_LIGHT = 8\n",
        "WINDOW_TEMP = 16\n",
        "LIGHT_RESO = 60\n",
        "TEMP_RESO = 1\n",
        "LENGTH_LIGHT = WINDOW_LIGHT * LIGHT_RESO\n",
        "LENGTH_TEMP = WINDOW_TEMP * TEMP_RESO\n",
        "\n",
        "gap = 4\n",
        "is_month = False\n",
        "light_net = CNN_Light(480, 128, 3, 128, 0).to(device)\n",
        "light_net.load_state_dict(torch.load('light_net.w', map_location=device))\n",
        "light_net.eval()\n",
        "temp_net = CNN_Temp(LENGTH_TEMP * 2, 0.5, 256).to(device)\n",
        "temp_net.load_state_dict(torch.load('temp_net_dropout_0.5.w', map_location=device))\n",
        "temp_net.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMgyjW805W47"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO9Nqr2o5YEC"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import scipy.io as sio\n",
        "import os\n",
        "from easydict import EasyDict\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
        "\n",
        "\n",
        "def test(opt):\n",
        "\n",
        "    temp_net = CNN_Temp(32, opt.dropout, opt.hidden).to(opt.device)\n",
        "\n",
        "    net_path = os.path.join(opt.net_dir, opt.net_name)\n",
        "    temp_net.load_state_dict(torch.load(net_path, map_location=opt.device))\n",
        "\n",
        "    if not os.path.exists(opt.output_folder):\n",
        "        os.makedirs(opt.output_folder)\n",
        "    if not os.path.exists(opt.output_fig_folder):\n",
        "        os.makedirs(opt.output_fig_folder)\n",
        "\n",
        "    temp_net.eval()\n",
        "\n",
        "    num = opt.num\n",
        "\n",
        "    for n in range(num):\n",
        "\n",
        "        data = sio.loadmat(os.path.join(opt.input_folder, str(n + 57) + '.mat'))\n",
        "        temp_test = data['test_temp']\n",
        "\n",
        "        results_temp = np.zeros((temp_test.shape[0], temp_test.shape[1]))\n",
        "\n",
        "        for i in range(temp_test.shape[0]):\n",
        "            temp = torch.from_numpy(temp_test[i, :, :]).float().to(opt.device)            \n",
        "            temp_result = temp_net(temp)\n",
        "\n",
        "            temp_result = torch.sigmoid(temp_result)\n",
        "\n",
        "            results_temp[i, :] = temp_result.cpu().squeeze().detach().numpy()\n",
        "    \n",
        "        #fig_temp = os.path.join(opt.output_fig_folder, 'temp_'+str(n+1)+'.png')\n",
        "        #plt.imshow(results_temp.transpose(), cmap='viridis', interpolation='nearest')\n",
        "        #plt.colorbar()\n",
        "        #plt.savefig(fig_temp)\n",
        "        #plt.clf()\n",
        "\n",
        "        path_temp = os.path.join(opt.output_folder, 'temp_' + str(n + 57) + '.mat')\n",
        "\n",
        "        sio.savemat(path_temp, {'results': results_temp})\n",
        "        print(n)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    opt = EasyDict()\n",
        "\n",
        "    opt.dropout = 0\n",
        "    opt.hidden = 256\n",
        "\n",
        "    opt.net_dir = '/content/'\n",
        "    opt.net_name = 'temp_net.w'\n",
        "\n",
        "    opt.num = 1\n",
        "\n",
        "    opt.output_folder = './results/Heatmaps_temp'\n",
        "    opt.output_fig_folder = './results/figs_temp'\n",
        "    opt.input_folder = '/content/'\n",
        "    opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    test(opt)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}